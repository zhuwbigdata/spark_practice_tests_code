{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "87a4339f-cc26-4446-83b0-5fd419c20c70",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Test 2, Question 45\n",
    "> **Hint:** In Databricks, import code for all questions via this URL:\n",
    "> \n",
    "> https://github.com/flrs/spark_practice_tests_code/raw/main/spark_practice_tests_code.dbc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2f909ada-99cb-406f-8df0-0f31d52f554c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Answer 1 (correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4a82b78f-40a6-432d-8c43-823eb0636daf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Question\n",
    "Do we still need to set with AQE?\n",
    "\n",
    "### Adaptive Query Execution (AQE)\n",
    "An optimization technique in Spark SQL that makes use of the runtime statistics to choose the most efficient query execution plan, which is enabled by default since Apache Spark 3.2.0. Spark SQL can turn on and off AQE by spark.sql.adaptive.enabled as an umbrella configuration. \n",
    "As of Spark 3.0, there are three major features in AQE: \n",
    "#### coalescing post-shuffle partitions, \n",
    "#### converting sort-merge join to broadcast join, \n",
    "#### skew join optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c7193aa7-5004-476d-a11a-15dd3833c449",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.shuffle.partitions\", 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9edca3fe-7135-4cbe-a61a-a5dbd2d4c733",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Answer 2 (incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6c3f712f-0536-4ce8-ad81-b36c5ec71945",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pyspark.config.set(spark.shuffle.partitions, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9e7b8a51-bd8b-45ce-aed6-488cc351332a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Answer 3 (incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "14f9adb3-dc1d-4e18-8cfa-4fddecdfdfcd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.get(\"spark.sql.shuffle.partitions\", 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8fef6132-53bf-4c40-b876-e17972c28fe8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Answer 4 (incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4a1dfb7c-aaf8-4c46-89c0-7367cb77a413",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pyspark.config.set(\"spark.sql.shuffle.partitions\", 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3da08153-8385-45d8-85f4-9d1e5156ec37",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Answer 5 (incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "741846ba-74a7-4878-9715-49e613b7b7e2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.aggregate.partitions\", 100)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "45",
   "notebookOrigID": 3688993815074047,
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
