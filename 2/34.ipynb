{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "87a4339f-cc26-4446-83b0-5fd419c20c70",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Test 2, Question 34\n",
    "> **Hint:** In Databricks, import code for all questions via this URL:\n",
    "> \n",
    "> https://github.com/flrs/spark_practice_tests_code/raw/main/spark_practice_tests_code.dbc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "269cdbaa-2d1b-475a-8d1c-0fb5fd7f8b27",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### pyspark.sql.functions.udf(f=None, returnType=StringType)[source]\n",
    "Creates a user defined function (UDF).\n",
    "\n",
    "f – python function if used as a standalone function\n",
    "\n",
    "returnType – the return type of the user-defined function. The value can be either a pyspark.sql.types.DataType object or a DDL-formatted type string.\n",
    "\n",
    "\n",
    "```\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "import random\n",
    "\n",
    "random_udf = udf(lambda: int(random.random() * 100), IntegerType()).asNondeterministic()\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "### lambda_expr ::=  \"lambda\" [parameter_list] \":\" expression\n",
    "\n",
    "Lambda expressions (sometimes called lambda forms) are used to create anonymous functions. \n",
    "\n",
    "```\n",
    "def func(a): return a + 1\n",
    "\n",
    "same as\n",
    "\n",
    "func = lambda a: a + 1\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce0bf962-8af0-4c63-8bed-7acbfb428c56",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./create_transactionsDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d890fa5-38f7-4189-b821-0b7ad99b9bb7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "evaluateTestSuccess = lambda x: True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2f909ada-99cb-406f-8df0-0f31d52f554c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Answer 1 (correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c7193aa7-5004-476d-a11a-15dd3833c449",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "from pyspark.sql import types as T\n",
    "evaluateTestSuccessUDF = udf(evaluateTestSuccess, T.BooleanType())\n",
    "result = transactionsDf.withColumn(\"result\", evaluateTestSuccessUDF(col(\"storeId\")))\n",
    "\n",
    "result.show()\n",
    "result.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8fef6132-53bf-4c40-b876-e17972c28fe8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Answer 2 (incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4a1dfb7c-aaf8-4c46-89c0-7367cb77a413",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "evaluateTestSuccessUDF = udf(evaluateTestSuccess)\n",
    "transactionsDf.withColumn(\"result\", evaluateTestSuccessUDF(storeId))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3da08153-8385-45d8-85f4-9d1e5156ec37",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Answer 3 (incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "741846ba-74a7-4878-9715-49e613b7b7e2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "from pyspark.sql import types as T\n",
    "evaluateTestSuccessUDF = udf(evaluateTestSuccess, T.IntegerType())\n",
    "transactionsDf.withColumn(\"result\", evaluateTestSuccess(col(\"storeId\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9e7b8a51-bd8b-45ce-aed6-488cc351332a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Answer 4 (incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "14f9adb3-dc1d-4e18-8cfa-4fddecdfdfcd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "evaluateTestSuccessUDF = udf(evaluateTestSuccess)\n",
    "result = transactionsDf.withColumn(\"result\", evaluateTestSuccessUDF(col(\"storeId\")))\n",
    "\n",
    "result.show()\n",
    "result.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9edca3fe-7135-4cbe-a61a-a5dbd2d4c733",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Answer 5 (incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6c3f712f-0536-4ce8-ad81-b36c5ec71945",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "from pyspark.sql import types as T\n",
    "evaluateTestSuccessUDF = udf(evaluateTestSuccess, T.BooleanType())\n",
    "transactionsDf.withColumn(\"result\", evaluateTestSuccess(col(\"storeId\")))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "34",
   "notebookOrigID": 3688993815074097,
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
