{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "87a4339f-cc26-4446-83b0-5fd419c20c70",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Test 2, Question 32\n",
    "> **Hint:** In Databricks, import code for all questions via this URL:\n",
    "> \n",
    "> https://github.com/flrs/spark_practice_tests_code/raw/main/spark_practice_tests_code.dbc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d02a86f3-c39b-4553-bfe1-11b1ffdf49f1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "https://spark.apache.org/docs/3.0.0/api/python/pyspark.sql.html#pyspark.sql.functions.sort_array\n",
    "\n",
    "###  pyspark.sql.functions.sort_array(col, asc=True)\n",
    "Collection function: sorts the input array in ascending or descending order according to the natural ordering of the array elements. \n",
    "\n",
    "Null elements will be placed at the beginning of the returned array in ascending order or at the end of the returned array in descending order.\n",
    "\n",
    "### DF.sort(*cols, **kwargs)\n",
    "\n",
    "Returns a new DataFrame sorted by the specified column(s).\n",
    "\n",
    "cols – list of Column or column names to sort by.\n",
    "\n",
    "ascending – boolean or list of boolean (default True). Sort ascending vs. descending. Specify list for multiple sort orders. If a list is specified, length of the list must equal length of the cols.\n",
    "\n",
    "```\n",
    "\n",
    "df.sort(df.age.desc())\n",
    "\n",
    "\n",
    "df.sort(\"age\", ascending=False)\n",
    "\n",
    "df.sort(asc(\"age\"))\n",
    "\n",
    "\n",
    "df.orderBy(desc(\"age\"), \"name\")\n",
    "\n",
    "df.orderBy([\"age\", \"name\"], ascending=[0, 1])\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "### built-in python: sorted or list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce0bf962-8af0-4c63-8bed-7acbfb428c56",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./create_itemsDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9edca3fe-7135-4cbe-a61a-a5dbd2d4c733",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Answer 1 (incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6c3f712f-0536-4ce8-ad81-b36c5ec71945",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sort_array, col\n",
    "\n",
    "itemsDf.withColumn('attributes', sort_array(col('attributes').desc())).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8fef6132-53bf-4c40-b876-e17972c28fe8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Answer 2 (incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4a1dfb7c-aaf8-4c46-89c0-7367cb77a413",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sort_array, desc\n",
    "\n",
    "itemsDf.withColumn('attributes', sort_array(desc('attributes'))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3da08153-8385-45d8-85f4-9d1e5156ec37",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Answer 3 (incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "741846ba-74a7-4878-9715-49e613b7b7e2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sort, col\n",
    "\n",
    "itemsDf.withColumn('attributes', sort(col('attributes'), asc=False)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2f909ada-99cb-406f-8df0-0f31d52f554c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Answer 4 (correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c7193aa7-5004-476d-a11a-15dd3833c449",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sort_array\n",
    "\n",
    "itemsDf.withColumn(\"attributes\", sort_array(\"attributes\", asc=False)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9e7b8a51-bd8b-45ce-aed6-488cc351332a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Answer 5 (incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "14f9adb3-dc1d-4e18-8cfa-4fddecdfdfcd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sort_array\n",
    "\n",
    "itemsDf.select(sort_array(\"attributes\")).show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "32",
   "notebookOrigID": 3688993815073304,
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
