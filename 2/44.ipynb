{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "87a4339f-cc26-4446-83b0-5fd419c20c70",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Test 2, Question 44\n",
    "> **Hint:** In Databricks, import code for all questions via this URL:\n",
    "> \n",
    "> https://github.com/flrs/spark_practice_tests_code/raw/main/spark_practice_tests_code.dbc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "10061e45-6935-438e-9b22-a1ffad4b086a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###  DF.alias(alias) - not used here\n",
    "Returns a new DataFrame with an alias set.\n",
    "alias – string, an alias name to be set for the DataFrame.\n",
    "\n",
    "### pyspark.sql.Column.alias(*alias, **kwargs)\n",
    "Returns this column aliased with a new name or names (in the case of expressions that return more than one column, such as explode).\n",
    "\n",
    "alias – strings of desired column names (collects all positional arguments passed)\n",
    "metadata – a dict of information to be stored in metadata attribute of the corresponding StructField (optional, keyword only argument)\n",
    "\n",
    "\n",
    "### pyspark.sql.functions.explode(col)\n",
    "Returns a new row for each element in the given array or map. Uses the default column name col for elements in the array and key and value for elements in the map unless specified otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce0bf962-8af0-4c63-8bed-7acbfb428c56",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./create_itemsDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "657a261f-684e-4b4e-8eed-873295461c52",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, explode\n",
    "\n",
    "articlesDf = itemsDf\n",
    "articlesDf.printSchema()\n",
    "articlesDf.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9e7b8a51-bd8b-45ce-aed6-488cc351332a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Answer 1 (incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "14f9adb3-dc1d-4e18-8cfa-4fddecdfdfcd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "articlesDf = itemsDf\n",
    "\n",
    "articlesDf = articlesDf.sort(\"count\",ascending=False).select(\"col\")\n",
    "articlesDf = articlesDf.groupby(\"col\").count()\n",
    "\n",
    "articlesDf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9edca3fe-7135-4cbe-a61a-a5dbd2d4c733",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Answer 2 (incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6c3f712f-0536-4ce8-ad81-b36c5ec71945",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, explode\n",
    "\n",
    "articlesDf = itemsDf\n",
    "\n",
    "articlesDf = articlesDf.select(explode(col(\"attributes\")))\n",
    "articlesDf = articlesDf.orderBy(\"count\").select(\"col\")\n",
    "articlesDf = articlesDf.groupby(\"col\").count()\n",
    "\n",
    "articlesDf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3da08153-8385-45d8-85f4-9d1e5156ec37",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Answer 3 (incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "741846ba-74a7-4878-9715-49e613b7b7e2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, explode\n",
    "\n",
    "articlesDf = itemsDf\n",
    "\n",
    "articlesDf = articlesDf.groupby(\"col\").count()\n",
    "articlesDf = articlesDf.select(explode(col(\"attributes\")))\n",
    "\n",
    "articlesDf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8fef6132-53bf-4c40-b876-e17972c28fe8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Answer 4 (incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4a1dfb7c-aaf8-4c46-89c0-7367cb77a413",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, explode\n",
    "\n",
    "articlesDf = itemsDf\n",
    "\n",
    "articlesDf = articlesDf.select(explode(col(\"attributes\")))\n",
    "articlesDf = articlesDf.orderBy(\"count\").select(\"col\")\n",
    "articlesDf = articlesDf.sort(\"count\",ascending=False).select(\"col\")\n",
    "\n",
    "articlesDf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2f909ada-99cb-406f-8df0-0f31d52f554c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Answer 5 (correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7193aa7-5004-476d-a11a-15dd3833c449",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, explode\n",
    "\n",
    "articlesDf2 = articlesDf.select(explode(col(\"attributes\")))\n",
    "\n",
    "articlesDf3 = articlesDf2.groupby(\"col\").count()\n",
    "\n",
    "articlesDf4 = articlesDf3.sort(\"count\",ascending=False).select(\"col\")\n",
    "\n",
    "articlesDf4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b08bec4-a02d-4c28-ad0c-40b1380d8b5a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, explode\n",
    "\n",
    "articlesDf2 = articlesDf.select(explode(articlesDf.attributes).alias(\"color\"))\n",
    "\n",
    "articlesDf3 = articlesDf2.groupby(\"color\").count()\n",
    "\n",
    "articlesDf4 = articlesDf3.sort(\"count\",ascending=False).select(\"color\")\n",
    "\n",
    "articlesDf4.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "44",
   "notebookOrigID": 3688993815073722,
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
